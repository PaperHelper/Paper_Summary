{"2106.03630": {"title": "Efficient Iterative Amortized Inference for Learning Symmetric and Disentangled Multi-Object Representations", "authors": ["Patrick Emami", "Pan He", "Sanjay Ranka", "Anand Rangarajan"], "publication": "Published in ICML'21. Code and data: https://github.com/pemami4911/EfficientMORL", "year": "2021", "tags": ["cs.CV", "cs.AI", "cs.LG"], "summary": "Deep learning has produced impressive results across multiple domains. It has become clear that the representations these models learn have fundamental limitations. Consider the problem of inferring a representation for a multi-object scene. We aim to develop such a method that incorporates three key inductive biases.\n\nWe assume that z generates the image x and that each element of z corresponds to a single object in the scene. To solve the inverse problem of obtaining z from x, we could compute the posterior distribution p. Bayes rule tells us that we also need the joint distribution p, which describes the image generation process. Since the latent dimension D can be 1, we use amortized variational inference.\n\nThe loss that gets minimized is L = L + I \u2212 I + 1 L, I+1 where the discount factor I\u2212 emphasizes the loss near i = 0 to place more weight on the encoder. Without re\ufb01nement, the HVAE consistently gets stuck in poor local minima early on during training and does not recover.\n\nThe approximate posterior collapses to the prior early on during training and never recovers. We applied mitigation strategies for this in three parts of the framework. We created a variant of the hierarchical prior where the arrows between z1, . . . , zL are reversed. We then considered replacing the prior in the re\ufb01nement loss KL term with p\u03b8.\n\nAll models use the Adam (Kingma & Ba, 2015) optimizer, a learning rate of 4e-4 with warm-up and exponential decay, gradient norm clipping to 5.0, and a mini-batch size of 96 \u00d7 96. We use K = 7 components for CLEVR6, K = 6 for Multi-dSprites, and K = 4 for Tetrominoes. To better understand the role of IAI in Ef\ufb01cientMORL and to justify decreasing I during training to reduce training time, we analyze the KL curves from \ufb01ve training runs.\n\nEf\ufb01cientMORL\u2019s decomposition performance is comparable to Slot Attention, MONet, and IODINE on all three environments. The model generalizes to larger numbers of objects at test time. We increase components K to 11 for CLEVR10 to improve segmentation and reconstruction.\n\nThe goal of this experiment is to compare the disentanglement quality of Ef\ufb01cientMORL\u2019s representations against the current state-of-the-art model Slot Attention on CLEVR. We measure the time taken for the forward and backward passes on 1 2080 Ti GPU with a mini-batch size of 4, images sizes 64 \u00d7 64, 96 \u00d7 96, and 128 \u00d7 128, and I \u2208 {0, 1, 3}. For comparison we use our own implementation of IODINE , GENESIS with K = 7, and Slot Attention with L = 3 in PyTorch.", "paper_char_count": 86594, "summary_char_count": 2521}, "2106.03310": {"title": "Zero-Shot Knowledge Distillation from a Decision-Based Black-Box Model", "authors": ["Zi Wang"], "publication": "Accepted to ICML 2021", "year": "2021", "tags": ["cs.LG", "cs.AI", "cs.CV"], "summary": "Training compact deep neural networks (Howard et al., 2017) ef\ufb01ciently has become an appealing topic be 1Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, Tennessee, USA. Correspondence to: Zi Wang <zwang84@vols.utk.edu>.\n\nWe propose to use sample robustness, i.e., the distance from a training sample to the decision boundaries of a DB3 teacher, to construct soft labels for DB3KD. Extensive experiments validate that the proposed approaches achieve competitive performance compared to existing KD methods in more relaxed scenarios.\n\nZero-Shot Knowledge Distillation from a Decision-Based Black-Box Model. replaces the Dirichlet distribution with a multivariate normal distribution to model the softmax output space of the generated samples. Although the vanilla KD is built with a black-box teacher , the whole training dataset is used for training. The student is trained by minimizing the loss function in Eq. .\n\nWe implement a binary search in the direction (xn 0 ) and \ufb01nd the i on the decision boundary. We then compute the sample robustness with Eq. in which xn Minimal Boundary Distance . Inspired by recent studies of decision-based black-box adversarial attack (Brendel et. al., 2017, 2018, Liu et al., 2019; Cheng et al. 2019)\n\nWe demonstrate the effectiveness of DB3KD with several widely used DNNs and datasets as follows. A LeNet5 with two convolutional layers is pre-trained on MNIST as the teacher, and a LeNet-5-1/5 is designed as the student networks. The same teacher and student networks as in are used but are trained and evaluated on the Fashion-MNIST dataset.\n\nStudent high-resolution, \ufb01ne-grained dataset FLOWERS102 (Nilsback & Zisserman, 2008) is used as the teacher, and the student is a ResNet. Training the student network via KD with a surrogate white-box teacher (Surrogate KD in Table 1) was used for simulating the scenario in which approach is used. We evaluate our approach with the three strategies for sample robustness calculation.\n\nDB3KD-MBD outperforms standard KD on all the experiments except for FLOWERS. Training with noise logits via KD does not work. Training a student with a surrogate teacher not only results in unsatisfactory performance, but also a dif\ufb01cult task due to the low capacity of the surrogate model.\n\nWith more queries, the student models perform slightly better, especially for deeper architectures and high-resolution datasets (FLOWERS102) The quality of a sample\u2019s soft label is largely related to its robustness against different classes. The MBD used for computing sample robustness shows a highly positive correlation with the number of queries.\n\nWe evaluate ZSDB3KD with a LeNet-5 and a Le net-5Half as the teacher. We generate 8000 samples for each class with a batch size of 200 for all the experiments. With 8k samples per class, the student\u2019s performance gets saturated and is comparable to the performance of standard KD.", "paper_char_count": 64838, "summary_char_count": 2944}, "2106.03041": {"title": "DAMSL: Domain Agnostic Meta Score-based Learning", "authors": ["John Cai", "Bill Cai", "Shengmei Shen"], "publication": "Accepted to CVPR 2021 L2ID Workshop", "year": "2021", "tags": ["cs.LG", "cs.AI", "cs.CV"], "summary": "Few-shot learning methods promise to solve one of the most challenging issues in deep learning: the reliance on copious amounts of labelled examples. The problem, however, is that many few- shot learning methods fail to perform well when there is a domain-shift. To solve the above issues, we propose Domain Agnostic Meta Score-based Learning.\n\nThe meta-learning module we use is the Graph Neural Network. In brief, a GNN acts on local operators of a graph G = , which for the fewshot learning case is fully connected. In the few-shot learning formulation, we can learn the edfe features using the current hidden vertices.\n\nWe train on miniImagenet and test on CropDisease , EuroSAT , ISIC and ChestX (in order of decreasing similarity) We also test on Places , Describable Textures Dataset , CIFAR-100 and Caltech256. The Github repo can be found here: Github link.\n\nAblation Studies on BSCD-FSL include a Linear Ensemble, Fine-Tuned en 3 and Score-based ProtoNets. The L-Ensem is a simple addition of the post-softmax scores from the two \ufb01ne-tuned feature encoders. The FT-GNN replaces the GNN module with an embedding MLP and a nearest centroid class.", "paper_char_count": 21559, "summary_char_count": 1154}, "2106.02820": {"title": "GraphMI: Extracting Private Graph Data from Graph Neural Networks", "authors": ["Zaixi Zhang", "Qi Liu", "Zhenya Huang", "Hao Wang", "Chengqiang Lu", "Chuanren Liu", "Enhong Chen"], "publication": "7 pages, 6 figures, accepted by IJCAI'21", "year": "2021", "tags": ["cs.LG", "cs.AI"], "summary": "Machine learning algorithms based on deep neural networks have achieved remarkable success in a range of domains. Many machine learning applications involve processing sensitive user data. Attackers may exploit the output or the parameters (i.e., whitebox attack) of machine learning models to potentially reveal sensitive information in training data.\n\nGNN models are commonly used for semisupervised node classi\ufb01cation. We propose Graph Model Inversion attack for edge reconstruction. The projected gradient module is able to tackle the edge discreteness via convex relaxation. The graph autoencoder module is designed to take all the information of node attributes, graph topology and target model parameters into consideration for graph reconstruction.\n\nIn previous work [Wu et al., 2016], researchers found feature in\ufb02uence to be an essential factor in incurring privacy risk. In our context of graph model inversion attack, sensitive features are edges. Here we want to characterize the correlation between edge in \ufb01uence and inversion risk. We show the attack performance of GraphMI on three GNNs. GraphMI achieves the best performance across nearly all the datasets.", "paper_char_count": 32876, "summary_char_count": 1174}, "2106.02801": {"title": "Trajectory Optimization of Chance-Constrained Nonlinear Stochastic Systems for Motion Planning and Control", "authors": ["Yashwanth Kumar Nakka", "Soon-Jo Chung"], "publication": "submitted to IEEE Transactions on Robotics", "year": "2021", "tags": ["cs.RO", "cs.AI", "eess.SY", "math.OC"], "summary": "Probabilistic approach can allow for integration with a higher-level discrete decision-making algorithm for information gathering and for safe exploration. Examples of autonomous systems that require safety guarantees under uncertainty include spacecraft with thrusters as actuators during proximity operations, powered descent on Mars and quadrotors \ufb02ying in turbulent winds.\n\nWe use gPC propagation to construct a DNOC problem that converges to the SNOC problem, asymptotically. We prove that the deterministic approximations are a subset of the respective chance constraints. We propose a SMPC method to control nonlinear stochastic differential equation. We solve the SMPC problem using the gPC-SCP method to track a potentially unsafe trajectory.\n\nThe gPC expansion approach was used for stability analysis and control design of uncertain systems. We extend prior work to incorporate nonlinear dynamics and include analysis on the deterministic approximation. We formulate convex constraints for linear and quadratic constraints in gPC space and use this formulation to design algorithms for motion planning and control.\n\nWe use the gPC method to project the SDE to an Ordinary Differential Equation in a higher dimensional space for propagating the dynamics. The dynamics of the system is modeled as a controlled diffusion process with It\u02c6o assumptions. In order to accommodate the unbounded uncertainty model in the dynamics, the feasible region XF de\ufb01ned as, XF is relaxed to a chance constraint.\n\nA convex relaxation of the individual chance constraint for an arbitrary distribution of the state vector x due to the nonlinearity in the system is intractable. A new deterministic relaxation for the quadratic chance constraint is used to bound the deviation of the random vector x. The joint constraints are split into multiple single chance constraints using Bonferroni's inequality method.\n\nUsing distributional robustness, Problem 1 is reformulated to the following Problem Problem Distributionally-Robust Chance-Constrained Stochastic Nonlinear Optimal Control. This approach transforms the SNOC problem that is in\ufb01nite dimensional in state (stochastic state) and time. We present an empirical evidence that using this approach does not lead to infeasibility.\n\nThe generalized Polynomial Chaos expansion theory is used to model uncertainty with \ufb01nite second-order moments xi. The polynomials are orthogonal with respect to a known density function \u03c1. We discuss the convergence of the gPC expansion to the true distribution and the error due to truncated polynomial approximation.\n\nWe use the Euler-Maruyama discretization method of the SDE for time integration. The discrete stochastic system is projected to a discrete deterministic system using the gPC method. For the beta and exponential distributions, gPC expansion represents the PDF well with just second order approximation.\n\nThe convex programming method used for trajectory optimization involves successive linearizations of the dynamics about a given trajectory and discretization for time integration. In Proposition 1, we present the conditions for existence and uniqueness of the solution to the projected system. While the projection operation preserves theexistence and uniqueness properties of the SDE, it might not conserve the controllability of the moments of the system.\n\nWe use the gPC projection method to derive a deterministic surrogate of the chance-constrained optimal control problem. We use sequential convex programming to solve Problem 3 and apply this technique to compute safe and optimal motion plans under uncertainty. The model predictive extension of gPC-SCP is applied for controlling a nonlinear robotic system under uncertainty and safety constraints.\n\nGPC-SCP: Generalized Polynomial Chaos-based Sequential Convex Programming. Convexi\ufb01ng the non-convex constraints and cost function about a nominal initial state and control trajectory. Constraints on the gPC state can be equivalently understood as probabilistic constraint of the form Pr \u2265 1. Sub-Optimality and Convergence of Problem 3.\n\nTheorem: Problem 3 with convex constraints is a sub-optimal surrogate for the stochastic nonlinear optimal control Problem 1. In Fig. 4, we illustrate the Lemmas 1, 2, 6 and 7 used in proving this theorem. The method is applied for planning a safe trajectory under uncertain obstacles and for controlling a nonlinear dynamical system under uncertainty.\n\nThe distributional robustness approach can be visualized as a robust ball around the robot\u2019s state for collision checking using the convex feasible subset Xs of the non-convex feasible space Xfree. The linear chance constraint under stochastic dynamics is projected to gPC space forming a second-order cone constraint. The terminal set is de\ufb01ned as a soft constraint on an ellipsoidal set and forms a semi-de \ufb01nite constraint in gPC states.\n\nCollision Checking with Deterministic Obstacles We derive a second-order cone constraint approximation of the circular obstacle in the gPC coordinates under the uncertainty in dynamics at any point in time t. The terminal constraint is de\ufb01ned as an ellipsoidal set around a terminal point. The conservative approximations we presented in this Section are a trade-off between the knowledge of moments available and the computational speed achieved by convex constraints. We outline the motion planning method using gPC-SCP for a dynamical system under uncertainty.\n\nWe present the continuous-time SMPC problem and then discuss the conditions for convergence and stability in terms of probability. The SMPC approach discussed below will ensure safety of the system in real-time at the control stage. The desired trajectory is computed for the nominal dynamics by using a deterministic motion planning algorithm.\n\nWe use a Stochastic Control Lyapunov Function as the terminal cost for guaranteeing the stability of the SDE system. We show that a decreasing optimal cost implies that the SMPC is a stabilizing controller. We make the following assumptions to ensure feasibility and constraint satisfaction of the Problem 5.\n\nJ\u2217 is the optimal cost and is the optiSk mal feasible trajectory of Problem 5 for the time horizon. J\u2217 Sk+1 is an exponential stabilizing control for the error dynamics in Problem 5. The SMPC control is computed using the SMPC.\n\nWe prove that the optimal cost of the \ufb01nitehorizon SMPC decreases with the time step k and then show that the decreasing optimal cost implies stability of the closed-loop system. This result can be extended to any k by moving the time horizon of Problem Decreasing Cost.\n\nWe formulate the SMPC such that recursive feasibility, constraint satisfaction, and stability is guaranteed. We then solve theSMPC problem by using the gPC approach and gPC-SCP problem. In the following Algorithm 2, we discuss the stochastic model predictive control algorithm for tracking a given desired trajectory. For the spacecraft simulator dynamics, we conduct an empirical study via simulation to demonstrate the safety provided by Algorithm 1 and 2 in comparison to the Gaussian collision constraint.\n\nWe validate the safety of the motion plans computed using gPC-SCP by tracking a sampled trajectory with the exponentially stable controller designed in for the nominal dynamics. We sample a trajectory x by using the projection \ud835\udc5c   \u00a0 \u00a0\u00a0   ...  ... ... ...\n\n2) SMPC-Based Trajectory Tracking: We apply the SMPC method described in Section V to track a trajectory designed using nominal dynamics. Since, the uncertainty in the dynamics and the obstacle location is not considered in the design of the nominal trajectory, it could be unsafe during operation. Algorithm 2 will enable safe operation, provided that Assumption 7 are satis\ufb01ed. 3) The guidance, navigation and control loop used for planning a distributionally-robust safe trajectory.", "paper_char_count": 109490, "summary_char_count": 7865}, "2106.02782": {"title": "On Perceptual Lossy Compression: The Cost of Perceptual Reconstruction and An Optimal Training Framework", "authors": ["Zeyu Yan", "Fei Wen", "Rendong Ying", "Chao Ma", "Peilin Liu"], "publication": "ICML 2021", "year": "2021", "tags": ["cs.IT", "cs.AI"], "summary": "Lossy compression is a fundamental problem in modern digital world for ef\ufb01cient transmission and storage of image, video and audio data. Recently, due in part to the roaring success of deep learning, the research of deep neural networks based compression has attracted much attention.\n\nTo improve the perceptual quality of reconstruction, a natural way is to minimize the deviation from the distribution of natural samples. For the lossy compression problem, a typical formulation incorporating an adversarial loss to optimize the encoder E and the decoder G through adversarial training is given by Lrec+Ladv. We propose a training framework that can achieve the lowest distortion under perfect perception constraint. It is based on GAN but avoids the balance between the distortion and adversarial losses.\n\nTheorem 1 indicates that when the distortion measure is MSE, replacing the perfect perception constraint d with the conditional distribution constraint does not change the optimal objective value. Under the condition that the data source is memoryless and stationary, it follows from theorem 1 that there exists an optimal solution to , under which the distributions of X and \u02c6X are the same.\n\nIn the proposed framework, E, G1, G2 and J are convolutional neural networks. The encoder E maps a 32 \u00d7 32 image into a d \u00d7 1 vector with each element be a quantized integer. G2 is trained to generate images of which the distribution is the same as that of X. When d = 0, degenerates to a pure generative adversarial network.\n\nWe demonstrate the theoretical \ufb01nding and the effectiveness of the proposed framework on the MNIST dataset. For 32 different bit rates, we train 32 encoder-decoder pairs by minimizing MSE-only loss and another 32 pairs by our proposed framework. Figure 3 presents the MSE loss in training G1 and G2 versus training epoch for six rate cases.", "paper_char_count": 56250, "summary_char_count": 1870}, "2106.02552": {"title": "Active Covering", "authors": ["Heinrich Jiang", "Afshin Rostamizadeh"], "publication": "ICML 2021", "year": "2021", "tags": ["cs.LG", "cs.AI", "stat.ML"], "summary": "Active learning is an increasingly important practical area of machine learning as the amount of data grows faster than the resources to label these datapoints. In this paper, we introduce a variant of the active learning problem, called active covering, where the goal is to label query all of the positive examples given an unlabeled dataset in as few total queries as possible.\n\nIn this section, we formulate the active covering problem. We are given an unlabeled dataset of n datapoints, X, and the goal is to minimize the number of label queries necessary until all positive examples are labeled. We provide the assumptions on the underlying distribution from which X is drawn from and establish the notion of excess query cost.\n\nWe establish a metric called excess query cost, which compares the learner to that of the optimal learner, which takes the optimal strategy given knowledge of X+. This learner is unattainable in practice, but serves as a theoretical limit in which to quantify the excess querycost of an algorithm with respect to, to be de\ufb01ned below.\n\nWe show an active approach inspired by Explore-then-Commit strategy that proceeds by randomly sampling a set of examples. We then commit to a greedy approach of choosing the closest unlabeled example to any positive example labeled thus far until all of the positive examples are labeled. We also provide the following lower bound, which shows that the of\ufb02ine learner cannot achieve a better rate (proof found in the appendix)\n\nThe goal of actively retrieving the positive labeled examples was studied as active search by Garnett et al. In our theoretical setting, the goal is to label query all of the positive examples with as few label queries as possible. A related line of work is learning under one-sided feedback, where the learner receives the true labels for only examples it predicted positively on.\n\nFor each of the datasets, we combine all of the data (i.e. any predetermined train/test/validation splits) into one dataset. We train a neural network on the initial sample and use the activations of the second-last layer as an embedding for the data. All of the methods will operate on this embedding instead of the original input. We tested on the following datasets: UCI Letters Recognition, MNIST, CIFAR10 and SVHN.", "paper_char_count": 57061, "summary_char_count": 2300}, "2106.02377": {"title": "A Survey on Deep Domain Adaptation for LiDAR Perception", "authors": ["Larissa T. Triess", "Mariella Dreissig", "Christoph B. Rist", "J. Marius Z\u00f6llner"], "publication": "Accepted at IEEE Intelligent Vehicles Symposium (IV) 2021 Workshop on Autonomy at Scale. 8 pages, 5 figures", "year": "2021", "tags": ["cs.CV", "cs.AI", "cs.LG"], "summary": "Deep learning techniques have shown impressive results in many perception applications. The majority of proposed methods are targeted towards DA techniques on 2D camera images. Most of these approaches aim for a global feature alignment and ignore local geometric information, which is crucial in 3D perception. The focus of this paper is to give an overview on DA methods that speci\ufb01cally address deep learning based LiDAR perception.\n\nThe literature does not provide any works on ensemble methods or target discriminative methods for LiDAR. The entropy minimization technique is one of the most often referenced baselines. Using simulators for autonomous driving applications gained a lot of interest in the past years and increased the research on sim-to-real DA.\n\nThis section presents the state of the art on DA for LiDARbased environment perception. The approaches are either data-driven, such as domain-invariant data representation, domain mapping, and normalization statistics, or modeldriven, like domain-Invariant feature learning.\n\nIn contrast to methods for camera images or generic point clouds, the number of papers that adversarially generate realistic LiDAR data is very limited. Most approaches use unmodi\ufb01ed image GANs, such as CycleGAN , and apply them to top-view projected images.\n\nThe primary use of normalization techniques is to improve training convergence, speed and performance. The effectiveness of per-domain statistics on LiDAR domain gaps has not been veri\ufb01ed experimentally. The methods are still not comparable, since they all use different datasets, task settings, label sets, and report different metrics.\n\nHand-crafted DA methods based on the explicit geometric properties of LiDAR data and their representation are the only ones that yield reasonable results on sensor-to-sensor domain shifts. None of the adversarial domain mapping techniques includes only four approaches, none of which is capable to generate realistic LiDar point clouds in 3D.", "paper_char_count": 48129, "summary_char_count": 1985}, "2106.02237": {"title": "Memory Approximate Message Passing", "authors": ["Lei Liu", "Shunqi Huang", "Brian M. Kurkoski"], "publication": "6 pages, 5 figures, accepted by IEEE ISIT 2021. arXiv admin note: substantial text overlap with arXiv:2012.10861", "year": "2021", "tags": ["cs.IT", "cs.AI", "eess.SP", "math.ST"], "summary": "Approximate message passing has attracted extensive research interest for this problem. AMP adopts a low-complexity matched \ufb01lter, so its complexity is as low as O per iteration. The Bayes optimality of AMP is derived in when the compression rate is larger than a certain threshold.\n\nWe propose a memory AMP using a lowcomplexity long-memory MF. Stricter orthogonality is required for MAMP to guarantee the asymptotic Gaussianity of estimation errors in MAMP. MAMP has comparable complexity to AMP and much lower complexity than OAMP/VAMP.\n\nOAMP/VAMP is Bayes optimal for right-unitarily-invariant matrices. OAMP is a symbol-bysymbol estimator, whose time complexity is as low as O. complexity of OAMP/ VAMP is dominated by LMMSELE, which costs O time complexity per iteration.\n\nMemory AMP involves a long memory {xi, i < t} at LMIE that is different from the non-memory LE in OAMP/VAMP. Matrix- vector multiplications instead of matrix inverse are involved. The complexity of MAMP is comparable to AMP, i.e., as low as O per iteration.\n\nMAMP and CAMP have the similar time and space complexity. OAMP/VAMP has higher complexity than AMP, CAMP and MAMP. MAMP is Bayes optimal if it has a unique \ufb01xed point. MSE of current iteration with optimized damping is not worse than that of the previous iteration.\n\nMAMP does not require the SVD structure of A. It only needs the right-unitarily invariance of A = 1, . . . , J \u2212 1 andJ i=1 d2 A. MAMP converges faster than CAMP to OAMP/VAMP. The proposed MAMP is not only Bayes-optimal, but also has comparable complexity.", "paper_char_count": 29462, "summary_char_count": 1561}, "2106.02206": {"title": "Stochastic Iterative Graph Matching", "authors": ["Linfeng Liu", "Michael C. Hughes", "Soha Hassoun", "Li-Ping Liu"], "publication": "To appear in ICML 2021", "year": "2021", "tags": ["cs.LG", "cs.AI", "stat.ML"], "summary": "Graph matching aims to \ufb01nd node correspondence among two or more graphs. We apply the stochastic softmax trick to the distribution of matchings. We then use a learning model to parameterize such a distribution to address the graph matching problem. The model is learned to maximize the expected reward under the matching distribution. This new model is able to explore a wider range of solutions.\n\nGraph Neural Networks were recently used as learning models for graph matching. The main idea in this class of work is to use a GNN to encode graph structures into node representation. nodes are matched based on their vector representation. Graph matching aims to find a matching M that is optimal with respect to an objective f.\n\nWe develop a model that predicts a distribution of matchings, instead of a single matching, for a training pair of graphs. The GS distribution \u02c6p\u03a6 is over the space of doubly stochastic matrices of the same size as S. The bottom nt rows of S can be viewed as \u201cdummy nodes\u201d in Gs so that the nt nodes in Gt have some chance that they all match to these dummy nodes.\n\nThe model nnr and the previous network nn share the same goal: maximizing the expected objective. The difference is that nnr can get information about the previous matching from \u03980, which helps to match more nodes or revise prior matchings. We apply the re\ufb01nement model to a multi-step procedure. The goal of training is to optimize the parameters of the GNN.\n\nWe use two datasets in this task, and follow the experiment setting from Xu et al. We compare our model with MCSPLIT and S-GWL (Xu et al., 2019a) We test our model on three tasks: a common graph matching task, a biochemistry application of matching reaction centers among molecular reactants, and a computer visionApplication of matching keypoints between images.\n\nSIGMA outperforms GMN and PCA-GM by over 10% of average Hit@1 score, and a 7.3% improvement upon CIE. SIGMA correctly identi\ufb01es keypoints with changed poses. We observe a 3.2% of hit@1 improvement over the DGMC.", "paper_char_count": 46588, "summary_char_count": 2032}}